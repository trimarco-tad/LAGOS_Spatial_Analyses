---
title: "Lake Water Quality Analysis"
author: "Tad Trimarco"
date: "2/22/2022"
output: html_document
---



```{r setup, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read}
#Lagos download script
#lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T)

#Load in lagos
lagos <- lagosne_load()


#Grab the lake centroid info
lake_centers <- lagos$locus

# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326)

#Grab the water quality data
nutr <- lagos$epi_nutr

#Look at column names
#names(nutr)
```

### Subset columns nutr to only keep key info that we want


```{r}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))

```


### Keep sites with at least 200 observations 

```{r}

#Look at the number of rows of dataset
#nrow(clarity_only)

chla_secchi <- clarity_only %>%
  filter(!is.na(chla),
         !is.na(secchi))

# How many observatiosn did we lose?
# nrow(clarity_only) - nrow(chla_secchi)


# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200)


```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')


```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake

mean_values_200 <- chla_secchi_200 %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))

#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid') 

#Make a map
mapview(mean_spatial,zcol='log10_mean_chl')
```


# Class work

## 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for
sites with at least 200 observations?

- Here, I just want a plot of chla vs secchi for all sites 

```{r}
ggplot(chla_secchi_200, aes(x = chla, y = secchi)) + 
  geom_point()
```


## Why might this be the case? 
It appears as though there isn't a strong trend between cholorophyll-a and secchi disk readings, though in general as chlorophyll-a increases, secchi disk depth decreases. This is likely because there a many different qater quality concerns that can cause low secchi disk readings, and cholorophyll-a is just one of them. As a result, there aren't any high-chlorophyll-a and high-secchi disk readings paired together, which indicates that if chlorophyll-a is high, secchi desk readings will be lower, but there are plenty low chlorophyll-a readings with low secchi disk readings, likely because some other water quality consitituent is impairing visibility.

## 2) What states have the most data? 

### 2a) First you will need to make a lagos spatial dataset that has the total 
number of counts per site.

```{r}

all_nutr <- nutr %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))

all_nutr_count <- all_nutr %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) 

spatial_nutr <- inner_join(spatial_lakes,all_nutr_count %>%
                              distinct(lagoslakeid, .keep_all = T),
                              by='lagoslakeid')

mapview(spatial_nutr)


```


### 2b) Second, you will need to join this point dataset to the us_boundaries 
data. 

```{r}
states <- us_states()
states <- states %>%
        st_transform(2163)

```


### 2c) Then you will want to group by state and sum all the observations in that
state and arrange that data from most to least toatl observations per state. 

```{r}
nutr_by_state <- spatial_nutr %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))
```

##3 Is there a spatial pattern in Secchi disk depth for lakes with at least 200 
observations?

```{r}
## Your code here

```


